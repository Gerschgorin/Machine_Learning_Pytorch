{"cells":[{"source":"We use image classification neural network to categorize new products of an e-commerce clothing retailer.\n","metadata":{"tags":[]},"id":"35d4e17b-eeb6-40dd-a140-7b949390e115","cell_type":"markdown","attachments":{}},{"source":"!pip install torchmetrics","metadata":{"executionCancelledAt":null,"executionTime":5389,"lastExecutedAt":1708543099364,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install torchmetrics","outputsMetadata":{"0":{"height":537,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"4de0b0ff-a211-41be-b90e-165e6038c9d7","cell_type":"code","execution_count":344,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.3.1)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.10.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>17.1->torchmetrics) (3.0.9)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\n"}]},{"source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1708543099414,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"},"id":"145bbc0f-4d15-4e7b-b796-5ec0d9ab7702","cell_type":"code","execution_count":345,"outputs":[]},{"source":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","metadata":{"executionCancelledAt":null,"executionTime":63,"lastExecutedAt":1708543099478,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","outputsMetadata":{"0":{"height":97,"type":"stream"},"2":{"height":137,"type":"stream"},"4":{"height":137,"type":"stream"},"6":{"height":137,"type":"stream"},"8":{"height":57,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"35ddad8f-fa43-4bb3-894b-afef8d0bfd59","cell_type":"code","execution_count":346,"outputs":[]},{"source":"# Data Presentation","metadata":{},"cell_type":"markdown","id":"e26af5a5-aad9-4910-8af7-ca2df661385f"},{"source":"print(type(train_data), len(train_data))\nprint(type(train_data[0]), len(train_data[0]))\n\nprint(type(train_data[0][0]), type(train_data[0][1]))\nprint(train_data[0][0].shape)\n\nprint(len(train_data.classes))","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1708543099531,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(type(train_data), len(train_data))\nprint(type(train_data[0]), len(train_data[0]))\n\nprint(type(train_data[0][0]), type(train_data[0][1]))\nprint(train_data[0][0].shape)\n\nprint(len(train_data.classes))","outputsMetadata":{"0":{"height":117,"type":"stream"}}},"cell_type":"code","id":"6fa970a4-762a-44ed-a00b-befc799ede81","outputs":[{"output_type":"stream","name":"stdout","text":"<class 'torchvision.datasets.mnist.FashionMNIST'> 60000\n<class 'tuple'> 2\n<class 'torch.Tensor'> <class 'int'>\ntorch.Size([1, 28, 28])\n10\n"}],"execution_count":347},{"source":"Data shape : 60000 x (28x28 + 1)\n\nInput : 60000 images de taille 28x28, noir&blanc(?)\n\nLabel : int de 0 Ã  9\n\n","metadata":{},"cell_type":"markdown","id":"5d44f838-01de-41e3-8ae2-2bfeca1a184d"},{"source":"# Network definition\n\n - Conv : 1 x 28x28 -> k x 28x28        (Without padding:26)\n - ReLU\n - MaxPool : k x 28x28 -> k x 14x14\n - Linear : k x 14x14 -> 10","metadata":{},"cell_type":"markdown","id":"12f86828-b0a7-482b-bc16-b632df2d8b64"},{"source":"k = 8  # output channels of the convolution\nn_class = 10","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1708543099578,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"k = 8  # output channels of the convolution\nn_class = 10"},"cell_type":"code","id":"8e1f9369-38e9-4087-94c1-5cb2e1de74b2","outputs":[],"execution_count":348},{"source":"A higher value for k only slighly increases the training time.","metadata":{},"cell_type":"markdown","id":"441e3884-4f58-4657-8e3a-854fddb270a3"},{"source":"class Classifier(nn.Module):\n    \n    def __init__(self, num_classes):\n        super(Classifier, self).__init__()\n        self.conv = nn.Conv2d(1, k, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flat = nn.Flatten()\n        self.lin = nn.Linear(k * 14**2, n_class)\n       \n    def forward(self, x):\n        x= self.conv(x)\n        x= self.relu(x)\n        x= self.maxpool(x)\n        x= self.flat(x)\n        x= self.lin(x)\n        return x","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1708543099630,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"class Classifier(nn.Module):\n    \n    def __init__(self, num_classes):\n        super(Classifier, self).__init__()\n        self.conv = nn.Conv2d(1, k, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flat = nn.Flatten()\n        self.lin = nn.Linear(k * 14**2, n_class)\n       \n    def forward(self, x):\n        x= self.conv(x)\n        x= self.relu(x)\n        x= self.maxpool(x)\n        x= self.flat(x)\n        x= self.lin(x)\n        return x"},"cell_type":"code","id":"6da2e4c6-a4bc-41a7-91c1-cd2ec5461e7e","outputs":[],"execution_count":349},{"source":"# Training","metadata":{},"cell_type":"markdown","id":"1e68f2b7-477e-4959-9382-a9250e853695"},{"source":"dataloader_train = DataLoader(train_data, shuffle = True, batch_size = 10)","metadata":{"executionCancelledAt":null,"executionTime":59,"lastExecutedAt":1708543099690,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"dataloader_train = DataLoader(train_data, shuffle = True, batch_size = 10)"},"cell_type":"code","id":"33b2f118-9204-4e05-b81e-6c92a2ea6e59","outputs":[],"execution_count":350},{"source":"def trainer(opti, model, n_epoch):\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(n_epoch):\n        running_loss = 0\n        nb_done = 0\n    \n        for imgs, lbls in dataloader_train:\n            opti.zero_grad()\n            outs = model(imgs)\n            loss = criterion(outs, lbls)\n            loss.backward()\n            opti.step()\n            \n            running_loss += loss.item()\n            nb_done += len(lbls)\n        print(f'Epoch: {epoch}, running loss: {running_loss/nb_done}')\n        # print average loss every epoch \n        \n    final_loss = running_loss / len(dataloader_train)  # average loss on the last epoch\n\n    ","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1708543099742,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def trainer(opti, model, n_epoch):\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(n_epoch):\n        running_loss = 0\n        nb_done = 0\n    \n        for imgs, lbls in dataloader_train:\n            opti.zero_grad()\n            outs = model(imgs)\n            loss = criterion(outs, lbls)\n            loss.backward()\n            opti.step()\n            \n            running_loss += loss.item()\n            nb_done += len(lbls)\n        print(f'Epoch: {epoch}, running loss: {running_loss/nb_done}')\n        # print average loss every epoch \n        \n    final_loss = running_loss / len(dataloader_train)  # average loss on the last epoch\n\n    "},"cell_type":"code","id":"c4651ec4-fdf6-4ef0-9944-3965e1bf1996","outputs":[],"execution_count":351},{"source":"model = Classifier(n_class)\nopti = optim.Adam(model.parameters(), lr=0.001)\n\ntrainer(opti = opti, model = model, n_epoch = 1)","metadata":{"executionCancelledAt":null,"executionTime":37329,"lastExecutedAt":1708543137072,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"model = Classifier(n_class)\nopti = optim.Adam(model.parameters(), lr=0.001)\n\ntrainer(opti = opti, model = model, n_epoch = 1)","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"653b00af-8910-4081-af4f-9dfbd5a6f7bf","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch: 0, running loss: 0.045706265081077196\n"}],"execution_count":352},{"source":"# Evaluation","metadata":{},"cell_type":"markdown","id":"e1720906-3060-42cf-b69c-cfb96115ff9f"},{"source":"dataloader_test = DataLoader(test_data, batch_size=10, shuffle=False)","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1708543137118,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"dataloader_test = DataLoader(test_data, batch_size=10, shuffle=False)"},"cell_type":"code","id":"66aa56f3-c146-4761-b293-fbea78c43172","outputs":[],"execution_count":353},{"source":"acc = Accuracy(task='multiclass', num_classes = 10)\nprec = Precision(task='multiclass', num_classes = 10, average=None)\nrec = Recall(task='multiclass', num_classes = 10, average=None)\n\nmodel.eval()\npredicted = []\nfor i, (imgs, lbls) in enumerate(dataloader_test):\n    out = model.forward(imgs.reshape(-1,1, 28,28))\n    cat = torch.argmax(out, dim=-1)\n    \n    predicted.extend(list(cat))    \n    prec(cat, lbls)    \n    rec(cat, lbls)\n    acc(cat, lbls)\n\nprecision = prec.compute().tolist()\nrecall = rec.compute().tolist()\naccuracy = acc.compute().item()\n\nprint(f\"Precision: {precision} \\n Recall: {recall} \\n Accuracy : {accuracy}\")\n","metadata":{"executionCancelledAt":null,"executionTime":10164,"lastExecutedAt":1708543147282,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"acc = Accuracy(task='multiclass', num_classes = 10)\nprec = Precision(task='multiclass', num_classes = 10, average=None)\nrec = Recall(task='multiclass', num_classes = 10, average=None)\n\nmodel.eval()\npredicted = []\nfor i, (imgs, lbls) in enumerate(dataloader_test):\n    out = model.forward(imgs.reshape(-1,1, 28,28))\n    cat = torch.argmax(out, dim=-1)\n    \n    predicted.extend(list(cat))    \n    prec(cat, lbls)    \n    rec(cat, lbls)\n    acc(cat, lbls)\n\nprecision = prec.compute().tolist()\nrecall = rec.compute().tolist()\naccuracy = acc.compute().item()\n\nprint(f\"Precision: {precision} \\n Recall: {recall} \\n Accuracy : {accuracy}\")\n","outputsMetadata":{"0":{"height":157,"type":"stream"}}},"cell_type":"code","id":"6360d276-61f4-474a-9df0-cb55b187c2d6","outputs":[{"output_type":"stream","name":"stdout","text":"Precision: [0.8608893752098083, 0.9936908483505249, 0.7691588997840881, 0.8402646780014038, 0.7644320130348206, 0.971727728843689, 0.6663190722465515, 0.9290060997009277, 0.9582089781761169, 0.9098591804504395] \n Recall: [0.7549999952316284, 0.9449999928474426, 0.8230000138282776, 0.8889999985694885, 0.8209999799728394, 0.9279999732971191, 0.6389999985694885, 0.9160000085830688, 0.9629999995231628, 0.968999981880188] \n Accuracy : 0.864799976348877\n"}],"execution_count":354}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
