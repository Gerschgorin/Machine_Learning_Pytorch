{"cells":[{"cell_type":"markdown","id":"06e96af4-1831-41d9-a3d7-76004d4f01a9","metadata":{},"source":["![Clothing Classifier Model](Clothing%20Classifier%20Model.png)\n"]},{"attachments":{},"cell_type":"markdown","id":"35d4e17b-eeb6-40dd-a140-7b949390e115","metadata":{"tags":[]},"source":["Fashion Forward is a new AI-based e-commerce clothing retailer.\n","They want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n","\n","As a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc.\n"]},{"cell_type":"code","execution_count":261,"id":"faf2e25e-6c2f-450d-95c1-e03d470cb2f1","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1706801981527,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run the cells below first"},"outputs":[],"source":["# Run the cells below first"]},{"cell_type":"code","execution_count":262,"id":"4de0b0ff-a211-41be-b90e-165e6038c9d7","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":5318,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1706801986845,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install torchmetrics","outputsMetadata":{"0":{"height":537,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.3.0.post0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.10.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>17.1->torchmetrics) (3.0.9)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":263,"id":"145bbc0f-4d15-4e7b-b796-5ec0d9ab7702","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1706801986895,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchmetrics import Accuracy, Precision, Recall"]},{"cell_type":"code","execution_count":264,"id":"35ddad8f-fa43-4bb3-894b-afef8d0bfd59","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":57,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1706801986953,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","outputsMetadata":{"0":{"height":97,"type":"stream"},"2":{"height":137,"type":"stream"},"4":{"height":137,"type":"stream"},"6":{"height":137,"type":"stream"},"8":{"height":57,"type":"stream"}}},"outputs":[],"source":["# Load datasets\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","\n","train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n","test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"code","execution_count":266,"id":"6fa970a4-762a-44ed-a00b-befc799ede81","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1706801987060,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(type(train_data))\nprint(len(train_data))\nprint(type(train_data[0]))\nprint(len(train_data[0]))\nprint(type(train_data[0][0]))\nprint(type(train_data[0][1]))\nprint(train_data[0][0].shape)\n#print(type(train_data[0][0][0]))\n#print(train_data[0][0][0].shape)\n#print(train_data[0][0][0][0].shape)\nprint(train_data[0][0][0][12][25])","outputsMetadata":{"0":{"height":177,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'torchvision.datasets.mnist.FashionMNIST'>\n","60000\n","<class 'tuple'>\n","2\n","<class 'torch.Tensor'>\n","<class 'int'>\n","torch.Size([1, 28, 28])\n","tensor(0.4667)\n"]}],"source":["print(type(train_data))\n","print(len(train_data))\n","print(type(train_data[0]))\n","print(len(train_data[0]))\n","print(type(train_data[0][0]))\n","print(type(train_data[0][1]))\n","print(train_data[0][0].shape)\n","#print(type(train_data[0][0][0]))\n","#print(train_data[0][0][0].shape)\n","#print(train_data[0][0][0][0].shape)\n","print(train_data[0][0][0][12][25])"]},{"cell_type":"code","execution_count":267,"id":"e4527024-9932-4869-93a6-96ddd7f5d2d1","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1706801987108,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#print(set([train_data[i][1] for i in range(len(train_data\nprint(len(train_data.classes))","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["10\n"]}],"source":["#print(set([train_data[i][1] for i in range(len(train_data\n","print(len(train_data.classes))"]},{"cell_type":"markdown","id":"5d44f838-01de-41e3-8ae2-2bfeca1a184d","metadata":{},"source":["Input : 60000 images de taille 28x28, noir&blanc (?)\n","Label : int de 0 Ã  9\n","\n","\n","Model : \n"," - Conv : 1 x 28x28 -> k x 28x28        WITHOUT PADDING:26\n"," - ReLU\n"," - MaxPool : k x 28x28 -> k x 14x14\n"," - Linear : k x 14x14 -> 10\n"]},{"cell_type":"code","execution_count":268,"id":"8c1b7110-571b-47fd-9892-7abfdf788135","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1706801987155,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"\n\ndataloader_train = DataLoader(train_data, shuffle = True, batch_size = 100)\n\n"},"outputs":[],"source":["\n","\n","dataloader_train = DataLoader(train_data, shuffle = True, batch_size = 100)\n","\n"]},{"cell_type":"code","execution_count":269,"id":"6da2e4c6-a4bc-41a7-91c1-cd2ec5461e7e","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1706801987203,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"k = 16\n\nmodel = nn.Sequential(\n    nn.Conv2d(1, k, kernel_size = 3, stride=1, padding=1),   \n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride = 2),\n    nn.Flatten(),\n    nn.Linear(k*14*14, 10)   # ????  pas de k ?!\n)\n\n#model(train_data[0][0])"},"outputs":[],"source":["k = 16\n","\n","model = nn.Sequential(\n","    nn.Conv2d(1, k, kernel_size = 3, stride=1, padding=1),   \n","    nn.ReLU(),\n","    nn.MaxPool2d(kernel_size=2, stride = 2),\n","    nn.Flatten(),\n","    nn.Linear(k*14*14, 10)   # ????  pas de k ?!\n",")\n","\n","#model(train_data[0][0])"]},{"cell_type":"code","execution_count":270,"id":"57486ebd-6c91-4c7f-8902-b630873c036e","metadata":{"executionCancelledAt":null,"executionTime":27968,"lastExecutedAt":1706802015172,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\nmodel.train()\n\nfor epoch in range(1):\n    for img, lbl in dataloader_train:\n        optimizer.zero_grad()\n        out = model(img)\n        label = nn.functional.one_hot(torch.tensor(lbl), num_classes = 10)\n        loss = criterion(out.double(), label.double())\n        loss.backward()\n        optimizer.step\n\n    "},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","model.train()\n","\n","for epoch in range(1):\n","    for img, lbl in dataloader_train:\n","        optimizer.zero_grad()\n","        out = model(img)\n","        label = nn.functional.one_hot(torch.tensor(lbl), num_classes = 10)\n","        loss = criterion(out.double(), label.double())\n","        loss.backward()\n","        optimizer.step\n","\n","    "]},{"cell_type":"code","execution_count":271,"id":"653b00af-8910-4081-af4f-9dfbd5a6f7bf","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1706802015223,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#model.eval()\n\n#predictions_vector = [model(img) for img, _ in test_data]\n#predictions = [torch.max(pred,1)[1] for pred in predictions_vector]\n\n#print(predictions)","outputsMetadata":{"0":{"height":537,"type":"stream"}}},"outputs":[],"source":["#model.eval()\n","\n","#predictions_vector = [model(img) for img, _ in test_data]\n","#predictions = [torch.max(pred,1)[1] for pred in predictions_vector]\n","\n","#print(predictions)"]},{"cell_type":"code","execution_count":272,"id":"6360d276-61f4-474a-9df0-cb55b187c2d6","metadata":{"executionCancelledAt":null,"executionTime":3245,"lastExecutedAt":1706802018469,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"acc = Accuracy(task='multiclass', num_classes = 10)\nprec = Precision(task='multiclass', num_classes = 10, average=None)\nrec = Recall(task='multiclass', num_classes = 10, average=None)\n\nmodel.eval()\n\ndataloader_test = DataLoader(test_data, batch_size=100, shuffle=False)\n\npredictions = []\nwith torch.no_grad():\n    for img, lbl in dataloader_test:\n        label = nn.functional.one_hot(torch.tensor(lbl), num_classes = 10)\n        pred_vect = model(img)\n        _, pred = torch.max(pred_vect, 1)  #prediction comme entier\n        predictions.append(pred)\n        \n        prec(pred_vect, label)    #(pred, lbl) pour des entier\n        rec(pred_vect, label)\n        acc(pred_vect, label)\n#        acc(pred.item(), lbl)\n    precision = prec.compute()\n    recall = rec.compute()\n    accuracy = acc.compute()\n\nprint(f\"Precision: {precision} \\n Recall: {recall} \\n Accuracy : {accuracy}\")\n    ","outputsMetadata":{"0":{"height":97,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision: tensor([0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000]) \n"," Recall: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) \n"," Accuracy : 0.0\n"]}],"source":["acc = Accuracy(task='multiclass', num_classes = 10)\n","prec = Precision(task='multiclass', num_classes = 10, average=None)\n","rec = Recall(task='multiclass', num_classes = 10, average=None)\n","\n","model.eval()\n","\n","dataloader_test = DataLoader(test_data, batch_size=100, shuffle=False)\n","\n","predictions = []\n","with torch.no_grad():\n","    for img, lbl in dataloader_test:\n","        label = nn.functional.one_hot(torch.tensor(lbl), num_classes = 10)\n","        pred_vect = model(img)\n","        _, pred = torch.max(pred_vect, 1)  #prediction comme entier\n","        predictions.append(pred)\n","        \n","        prec(pred_vect, label)    #(pred, lbl) pour des entier\n","        rec(pred_vect, label)\n","        acc(pred_vect, label)\n","#        acc(pred.item(), lbl)\n","    precision = prec.compute()\n","    recall = rec.compute()\n","    accuracy = acc.compute()\n","\n","print(f\"Precision: {precision} \\n Recall: {recall} \\n Accuracy : {accuracy}\")\n","    "]},{"cell_type":"code","execution_count":275,"id":"39178cce-088b-42c9-ba96-6915f1c8fdc5","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1706802043320,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#print(predictions)","outputsMetadata":{"0":{"height":537,"type":"stream"}}},"outputs":[],"source":["#print(predictions)"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
